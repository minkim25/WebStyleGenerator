{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.similarities import WmdSimilarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "stop_words = stopwords.words('english')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\young\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "def preprocess(doc):\n",
    "    doc = doc.lower()  # Lower the text.\n",
    "    doc = word_tokenize(doc)  # Split into words.\n",
    "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
    "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('websites/ParsedWebsitesCleanSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ea7fb39a84aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwmd_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\young\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4043\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4045\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4047\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-cc150b83d533>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Lower the text.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Split into words.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Remove stopwords.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "wmd_corpus = data['text'].apply(preprocess).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = WmdSimilarity(wmd_corpus, model, num_best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(instance,open('WordMoverDistance-Instance.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = pickle.load(open('WordMoverDistance-WebInstanceSLIM.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_text(val):\n",
    "    if val:\n",
    "        reg = re.compile(r'\\b\\w{3,20}\\b')\n",
    "        temp = reg.findall(val)\n",
    "        temp_set = set(temp)\n",
    "        temp_list = list(temp_set)\n",
    "        if len(temp_list) < 20:\n",
    "            temp2 = temp_list\n",
    "        elif len(temp_list) < 50:\n",
    "            temp2 = temp_list[10:]\n",
    "        elif len(temp_list) < 100:\n",
    "            temp2 = temp_list[30:]\n",
    "        else:\n",
    "            temp2 = temp_list[50:100]\n",
    "        result = \" \".join(temp2) \n",
    "        return (\"...\" + result + \"....\")\n",
    "    else:\n",
    "        return \"Empty string found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityQuery(description):  \n",
    "    description = description.replace('data', '')\n",
    "    query = preprocess(description)\n",
    "    sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "    # Print the query and the retrieved documents, together with their similarities.\n",
    "    results = []\n",
    "#     print(description)\n",
    "    for i in range(3):\n",
    "\n",
    "        row = []\n",
    "        try:\n",
    "            row.append(documents[sims[i][0]][0]) # WebsiteKey\n",
    "            row.append(documents[sims[i][0]][2]) # Website\n",
    "            row.append(documents[sims[i][0]][3]) # Colors\n",
    "            row.append(documents[sims[i][0]][4]) # Fonts\n",
    "            row.append(documents[sims[i][0]][5]) # Text\n",
    "            row.append(sims[i][1])    # Similarity\n",
    "            results.append(row)\n",
    "        except IndexError:\n",
    "            row.append(\"sampleWebsiteKey\") # WebsiteKey\n",
    "            row.append(\"sampleWebsite\") # Website\n",
    "            row.append([['#FFFFFF', 1],['#FFFFFF', 1],['#FFFFFF', 1]]) # Colors\n",
    "            row.append([['font-family:Arial', '1'],['font-family:Arial', '1'],['font-family:Arial', '1']]) # Fonts\n",
    "            row.append(\"sampleText\") # Text\n",
    "            row.append(\"0.0\")    # Similarity\n",
    "            results.append(row)\n",
    "            break\n",
    "        \n",
    "    resultsDF = pd.DataFrame(results)\n",
    "    #resultsDF.to_csv(description + '.csv')\n",
    "\n",
    "    resultsDF.columns = ['WebsiteKey','Website','Colours','Fonts','Text','Similarity']\n",
    "    resultsDF['Fonts'] = resultsDF['Fonts'].replace({'\\\" \\'': '\\\", \\'', \"\\' \\'\": \"\\', \\'\", '(\\r\\n)': ','}, regex=True)\n",
    "    resultsDF['Colours'] = resultsDF['Colours'].replace({' ': ', '}, regex=True)\n",
    "    resultsDF['Text'] = resultsDF['Text'].apply(regex_text)\n",
    "    resultsDF = resultsDF.sort_values(by=['Similarity'],ascending=False)\n",
    "    return resultsDF#.style.set_properties(subset=['Text'], **{'width': '350px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WebsiteKey</th>\n",
       "      <th>Website</th>\n",
       "      <th>Colours</th>\n",
       "      <th>Fonts</th>\n",
       "      <th>Text</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sampleWebsiteKey</td>\n",
       "      <td>sampleWebsite</td>\n",
       "      <td>[[#FFFFFF, 0], [#FFFFFF, 0], [#FFFFFF, 0]]</td>\n",
       "      <td>[[font-family:Arial, 0], [font-family:Arial, 0...</td>\n",
       "      <td>...sampleText....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WebsiteKey        Website  \\\n",
       "0  sampleWebsiteKey  sampleWebsite   \n",
       "\n",
       "                                      Colours  \\\n",
       "0  [[#FFFFFF, 0], [#FFFFFF, 0], [#FFFFFF, 0]]   \n",
       "\n",
       "                                               Fonts               Text  \\\n",
       "0  [[font-family:Arial, 0], [font-family:Arial, 0...  ...sampleText....   \n",
       "\n",
       "  Similarity  \n",
       "0        0.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarityQuery('I will talk about some cool topics in programming')\n",
    "similarityQuery('dsfsaweas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def generateResult(description):\n",
    "    df = similarityQuery(description)\n",
    "    dict = {}\n",
    "    flag_f = False\n",
    "    try:\n",
    "        aF = [ast.literal_eval(df.iloc[0]['Fonts']), ast.literal_eval(df.iloc[1]['Fonts']), ast.literal_eval(df.iloc[2]['Fonts'])]\n",
    "        aC = [ast.literal_eval(df.iloc[0]['Colours']), ast.literal_eval(df.iloc[1]['Colours']), ast.literal_eval(df.iloc[2]['Colours'])]\n",
    "        aT = [df.iloc[0]['Text'], df.iloc[1]['Text'], df.iloc[2]['Text']]\n",
    "    except:\n",
    "        aF = [df.iloc[0]['Fonts']]\n",
    "        aC = [df.iloc[0]['Colours']]\n",
    "        aT = [df.iloc[0]['Text']] \n",
    "        flag_f = True\n",
    "    \n",
    "    font_size = []\n",
    "    for i in range(len(aF)):\n",
    "        font_size.append(len(aF[i]))\n",
    "        for j in range(len(aF[i])):\n",
    "            aF[i][j][1] = int(aF[i][j][1])\n",
    "    \n",
    "    color_size = []\n",
    "    for i in range(len(aC)):\n",
    "        color_size.append(len(aC[i]))\n",
    "        for j in range(len(aC[i])):\n",
    "            if (' ' in aC[i][j][0]) or (',' in aC[i][j][0]):\n",
    "                aC[i][j][0] = aC[i][j][0].replace(' ','')\n",
    "                aC[i][j][0] = aC[i][j][0].replace(',','')\n",
    "    \n",
    "    if flag_f:\n",
    "        font_size = [0]\n",
    "        color_size = [0]\n",
    "        \n",
    "    dict['total'] = range(len(aC))\n",
    "    dict['f_size'] = font_size\n",
    "    dict['c_size'] = color_size\n",
    "    dict['fonts'] = aF\n",
    "    dict['colors'] = aC\n",
    "    dict['texts'] = aT\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': range(0, 3),\n",
       " 'f_size': [3, 3, 3],\n",
       " 'c_size': [3, 3, 3],\n",
       " 'fonts': [[[\"font-family:'fl-icons'\", 4],\n",
       "   [\"font-family:'object-fit: cover\", 3],\n",
       "   ['font-family:\"fl-icons\" !important', 2]],\n",
       "  [['font-family:Arial', 9],\n",
       "   ['font-family: \"revicons\"', 8],\n",
       "   ['font-family: FontAwesome', 5]],\n",
       "  [['font-family:\"Barlow Condensed\",arial', 9],\n",
       "   ['font-family:\"Lato\",arial', 7],\n",
       "   ['font-family:arial', 4]]],\n",
       " 'colors': [[['#446084', 15], ['#f1f1f1', 6], ['#d26e4b', 2]],\n",
       "  [['#337ab7', 7], ['#f5f5f5', 6], ['#1980B6', 6]],\n",
       "  [['#f9f9f9', 2], ['#5B5B5', 1], ['#e6e6e6', 1]]],\n",
       " 'texts': ['...strain current Hot new Account banner Sale right last well taken saying col column submit level wholesale made best strong produce Tour gallery every image little season are few before when dysfunction wondering transparent living place our used Contact receive should Cart favored intercourse Border slider mushroom syringes very visible....',\n",
       "  '...modal fight VIDEO Story Video image Add pull plus share this LECTURE white Remember target blank role radius suggest body from Mobile account You Menu was twitter ref font one their document display them Interesting have interest SIGN AND History Science inventor but Coil Assembly password world SEARCH could about Short Sign switch....',\n",
       "  '...The fair THE Volleyball Cite Baseball personal DEADLINE rum footer LOGOS GOLF Athletic body sports LEADERSHIP responsibility Skip ATHLETE Softball Home for educational Search GENERAL practice Twitter offering athletic inBeing forum process Composite academic Leadership theme active BASEBALL....']}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateResult(\"university\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
